{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65210f62-ce9b-4779-8593-8c52017c16a8",
   "metadata": {},
   "source": [
    "# Analyze CPP_V values from MD trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3664c5-421d-4656-9828-cc3275be46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import MDAnalysis as mda\n",
    "import tqdm\n",
    "import joblib\n",
    "from joblib import Parallel, delayed\n",
    "from joblib._parallel_backends import LokyBackend\n",
    "from joblib.parallel import Parallel as JoblibParallel\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a7eefc3-c7b5-4417-a3a7-5ca246c27126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined variables\n",
    "NUM_CPU = 64 # number of CPU cores to allocate to task\n",
    "\n",
    "PROTONATED_MD_TRAJECTORY_BASE_DIR = \"data/MD_trajectory_protonated\" # half-protonated systems\n",
    "NEUTRAL_MD_TRAJECTORY_BASE_DIR = \"data/MD_trajectory_neutral\" # fully-neutral systems\n",
    "\n",
    "PROTONATED_OUTPUT_FILE = \"results/CPP_V_results_protonated.csv\" # where to save CPP results for protonated trajectories\n",
    "NEUTRAL_OUTPUT_FILE = \"results/CPP_V_results_neutral.csv\" # where to save CPP results for neutral trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa3850-17a3-44a1-b52d-a1dac7a36063",
   "metadata": {},
   "outputs": [],
   "source": [
    "protonated_trajectory_names = [\n",
    "    name for name in os.listdir(PROTONATED_MD_TRAJECTORY_BASE_DIR)\n",
    "    if os.path.isdir(os.path.join(PROTONATED_MD_TRAJECTORY_BASE_DIR, name))\n",
    "]\n",
    "protonated_trajectory_dirs = [\n",
    "    os.path.join(PROTONATED_MD_TRAJECTORY_BASE_DIR, name, \"openmm\")\n",
    "    for name in protonated_trajectory_names\n",
    "]\n",
    "\n",
    "# Filter neutral system directories that contain \"YX\" or \"LM\"\n",
    "neutral_trajectory_names = [\n",
    "    name for name in os.listdir(NEUTRAL_MD_TRAJECTORY_BASE_DIR)\n",
    "    if os.path.isdir(os.path.join(NEUTRAL_MD_TRAJECTORY_BASE_DIR, name)) and (\"LM\" in name)#(\"YX\" in name or \"LM\" in name)\n",
    "]\n",
    "neutral_trajectory_dirs = [\n",
    "    os.path.join(NEUTRAL_MD_TRAJECTORY_BASE_DIR, name, \"openmm\")\n",
    "    for name in neutral_trajectory_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f9fad-67da-46de-b51b-2a8ac487b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ionizable lipid atom dictionary for LM_2019 LNPs\n",
    "il_atom_dict = pd.read_csv(\"/data/il_atom_dict_LM_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6aa3bd4-25d9-461a-8f7e-67c15e8c62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk to define functions relevant to computing CPP_V\n",
    "\n",
    "# Define excluded residues\n",
    "excluded_residues = {\"CLA\", \"CHL1\", \"TIP3\", \"SOD\", \"DOPE\", \"DSPC\", \"DOTAP\"}\n",
    "\n",
    "# Function to identify residue names\n",
    "def identify_residues(u, excluded_residues):\n",
    "    residue_names = set(res.resname for res in u.residues)\n",
    "    filtered_residues = [res for res in residue_names if res not in excluded_residues]\n",
    "    # If only one residue, treat it as neutral and leave protonated blank\n",
    "    if len(filtered_residues) == 1:\n",
    "        return None, filtered_residues[0]\n",
    "    # Find potential protonated and neutral residues\n",
    "    potential_protonated = [res for res in filtered_residues if \"H\" in res]\n",
    "    potential_neutral = [res for res in filtered_residues if res not in potential_protonated]\n",
    "    # Choose protonated residue as the one with more \"H\" characters\n",
    "    protonated_residue = max(potential_protonated, key=lambda res: res.count(\"H\"), default=None)\n",
    "    # Choose neutral residue as any other residue (fallback to None if empty)\n",
    "    neutral_residue = next((res for res in filtered_residues if res != protonated_residue), None)\n",
    "    return protonated_residue, neutral_residue\n",
    "\n",
    "# Function to remove outliers using 1.5*IQR\n",
    "def remove_outliers(data):\n",
    "    q1 = np.percentile(data, 25)\n",
    "    q3 = np.percentile(data, 75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return data[(data >= lower_bound) & (data <= upper_bound)]\n",
    "\n",
    "def compute_cpp_for_residue(dcd_files, topology_file, residue_name, head_atoms, anchor_atom, tail1_ends, tail2_ends, tail3_ends):\n",
    "    \"\"\"\n",
    "     Compute the CPP_V metric for a specific residue across multiple DCD files.\n",
    "\n",
    "     Parameters:\n",
    "         dcd_files (list): List of DCD file paths.\n",
    "         topology_file (str): Path to the topology file.\n",
    "         residue_name (str): Name of the residue to analyze.\n",
    "         head_atoms (list): List of head atom names.\n",
    "         anchor_atom (list): List containing the anchor atom name.\n",
    "         tail1_ends (list): List of tail1 end atom names.\n",
    "         tail2_ends (list): List of tail2 end atom names.\n",
    "         tail3_ends (list): List of tail3 end atom names.\n",
    "\n",
    "     Returns:\n",
    "         np.ndarray: Final concatenated CPP array across all DCD files.\n",
    "     \"\"\"\n",
    "    cpp_arrays = []\n",
    "    for dcd_file in dcd_files:\n",
    "        u = mda.Universe(topology_file, dcd_file)\n",
    "        n_frames = len(u.trajectory)\n",
    "        residue_group = u.select_atoms(f\"resname {residue_name}\")\n",
    "        n_molecules = len(residue_group.residues)\n",
    "    \n",
    "        coordinates_array = []  # List to store coordinates per molecule per frame\n",
    "    \n",
    "        for frame_idx, ts in enumerate(u.trajectory):\n",
    "            frame_coords = []\n",
    "            for mol_idx, residue in enumerate(residue_group.residues):\n",
    "                atom_group = residue.atoms\n",
    "                all_atom_names = [atom.name for atom in atom_group]\n",
    "    \n",
    "                # Collect coordinates for all atoms in the molecule\n",
    "                molecule_coords = np.full((len(all_atom_names), 3), np.nan)  # Initialize with NaN\n",
    "                for atom_idx, atom_name in enumerate(all_atom_names):\n",
    "                    atom = atom_group.select_atoms(f\"name {atom_name}\")\n",
    "                    if len(atom) == 1:\n",
    "                        molecule_coords[atom_idx, :] = atom.positions[0]\n",
    "                frame_coords.append(molecule_coords)\n",
    "            coordinates_array.append(frame_coords)\n",
    "    \n",
    "        coordinates_array = np.array(coordinates_array)  # Convert to numpy array\n",
    "    \n",
    "        cpp_array = np.zeros((n_frames, n_molecules))\n",
    "        for frame_idx in range(n_frames):\n",
    "            for mol_idx in range(n_molecules):\n",
    "                molecule_coords = coordinates_array[frame_idx, mol_idx]\n",
    "                all_atom_names = [atom.name for atom in residue_group.residues[mol_idx].atoms]\n",
    "    \n",
    "                # Ensure anchor_atom exists in all_atom_names\n",
    "                if anchor_atom[0] not in all_atom_names:\n",
    "                    cpp_array[frame_idx, mol_idx] = np.nan\n",
    "                    continue\n",
    "    \n",
    "                anchor_pos = molecule_coords[all_atom_names.index(anchor_atom[0])]\n",
    "    \n",
    "                # **Filter out NaN values before calculating distances**\n",
    "                valid_tail1_ends = [t for t in tail1_ends if t in all_atom_names]\n",
    "                valid_tail2_ends = [t for t in tail2_ends if t in all_atom_names]\n",
    "                valid_tail3_ends = [t for t in tail3_ends if t in all_atom_names]\n",
    "    \n",
    "                tail1_distances = np.linalg.norm(\n",
    "                    molecule_coords[[all_atom_names.index(t) for t in valid_tail1_ends]] - anchor_pos, axis=1\n",
    "                ) if valid_tail1_ends else np.array([])\n",
    "    \n",
    "                tail2_distances = np.linalg.norm(\n",
    "                    molecule_coords[[all_atom_names.index(t) for t in valid_tail2_ends]] - anchor_pos, axis=1\n",
    "                ) if valid_tail2_ends else np.array([])\n",
    "    \n",
    "                tail3_distances = np.linalg.norm(\n",
    "                    molecule_coords[[all_atom_names.index(t) for t in valid_tail3_ends]] - anchor_pos, axis=1\n",
    "                ) if valid_tail3_ends else np.array([])\n",
    "    \n",
    "                # Skip if any tail distances are missing\n",
    "                if len(tail1_distances) == 0 and len(tail2_distances) == 0 and len(tail3_distances) == 0:\n",
    "                    cpp_array[frame_idx, mol_idx] = np.nan\n",
    "                    continue\n",
    "    \n",
    "                #lc = 0.3 + np.mean([np.max(tail1_distances), np.max(tail2_distances), np.max(tail3_distances)])\n",
    "                lc = 0.3 + np.mean([np.max(dist) for dist in [tail1_distances, tail2_distances, tail3_distances] if dist.size > 0])\n",
    "    \n",
    "                # Compute head and tail radii\n",
    "                head_xy_coords = molecule_coords[[all_atom_names.index(t) for t in head_atoms if t in all_atom_names]][:, :2]\n",
    "                if len(head_xy_coords) < 2:\n",
    "                    cpp_array[frame_idx, mol_idx] = np.nan\n",
    "                    continue\n",
    "                max_head_distance = np.max(np.linalg.norm(head_xy_coords[:, np.newaxis] - head_xy_coords[np.newaxis, :], axis=-1))\n",
    "                head_radius = (max_head_distance + 0.3) / 2\n",
    "    \n",
    "                tail_xy_coords = molecule_coords[[all_atom_names.index(t) for t in valid_tail1_ends + valid_tail2_ends + valid_tail3_ends]][:, :2]\n",
    "                if len(tail_xy_coords) < 2:\n",
    "                    cpp_array[frame_idx, mol_idx] = np.nan\n",
    "                    continue\n",
    "                max_tail_distance = np.max(np.linalg.norm(tail_xy_coords[:, np.newaxis] - tail_xy_coords[np.newaxis, :], axis=-1))\n",
    "                tail_radius = (max_tail_distance + 0.3) / 2\n",
    "    \n",
    "                # Compute CPP metric\n",
    "                a0 = np.pi * (head_radius**2)\n",
    "                v = (1 / 3) * np.pi * lc * ((head_radius**2) + (head_radius * tail_radius) + (tail_radius**2))\n",
    "                cpp_array[frame_idx, mol_idx] = v / (a0 * lc)\n",
    "    \n",
    "        cpp_arrays.append(cpp_array)\n",
    "    \n",
    "    final_cpp_array = np.concatenate(cpp_arrays, axis=0)\n",
    "    return final_cpp_array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e2f6c7-1266-4b14-8e7b-fee8877a9a24",
   "metadata": {},
   "source": [
    "## Half-protonated systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c47be7-3a3d-49dd-9b6b-c67c0059e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_names = protonated_trajectory_names\n",
    "batch_dirs = protonated_trajectory_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f726405-068f-4f67-a991-d7cd093019b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trajectory(protonated_trajectory_name, protonated_trajectory_dir):\n",
    "    try:\n",
    "        dcd_files = [f for f in os.listdir(protonated_trajectory_dir) if f.endswith(\".dcd\")]\n",
    "        dcd_indices = sorted([\n",
    "            int(f.split(\"_\")[1].split(\".\")[0])\n",
    "            for f in dcd_files\n",
    "            if f.split(\"_\")[1].split(\".\")[0].isdigit()\n",
    "        ], reverse=True)\n",
    "        last50_files = [os.path.join(protonated_trajectory_dir, f\"step3_{i}.dcd\") for i in range(150, 100, -1)]\n",
    "\n",
    "        topology_file = os.path.join(os.path.dirname(protonated_trajectory_dir), \"openmm\", \"system.psf\")\n",
    "\n",
    "        u = mda.Universe(topology_file, last50_files[0])\n",
    "        protonated_residue, neutral_residue = identify_residues(u, excluded_residues)\n",
    "\n",
    "        il_row = il_atom_dict[il_atom_dict[\"folder_name\"] == protonated_trajectory_name].iloc[0]\n",
    "        head_atoms = il_row[\"head_total\"].split(\",\") if isinstance(il_row[\"head_total\"], str) else []\n",
    "        anchor_atom = il_row[\"anchor_atom\"].split(\",\") if isinstance(il_row[\"anchor_atom\"], str) else []\n",
    "        tail1_ends = il_row[\"tail1_terminal\"].split(\",\") if isinstance(il_row[\"tail1_terminal\"], str) else []\n",
    "        tail2_ends = il_row[\"tail2_terminal\"].split(\",\") if isinstance(il_row[\"tail2_terminal\"], str) else []\n",
    "        tail3_ends = []\n",
    "\n",
    "        def compute_stats(dcd_list, residue):\n",
    "            cpp = compute_cpp_for_residue(\n",
    "                dcd_list, topology_file, residue, head_atoms, anchor_atom, tail1_ends, tail2_ends, tail3_ends\n",
    "            )\n",
    "        \n",
    "            # cpp is (n_frames, n_molecules)\n",
    "            frame_means = np.nanmean(cpp, axis=1)  #row-wise mean across molecules for each frame\n",
    "            molecule_means = np.nanmean(cpp, axis=0) #column-wise mean across frames for each molecule\n",
    "            std_per_frame = np.nanstd(frame_means)\n",
    "            std_per_molecule = np.nanstd(molecule_means)\n",
    "        \n",
    "            #cpp_clean = remove_outliers(cpp)\n",
    "            cpp_clean = cpp\n",
    "        \n",
    "            return {\n",
    "                \"mean\": np.mean(cpp_clean),\n",
    "                \"std\": np.std(cpp_clean),\n",
    "                \"sem\": np.std(cpp_clean) / np.sqrt(len(cpp_clean)) if len(cpp_clean) > 0 else np.nan,\n",
    "                \"std_per_frame\": std_per_frame,\n",
    "                \"std_per_molecule\": std_per_molecule\n",
    "            }\n",
    "    \n",
    "        # Compute stats for each chunk + combined \"all\"\n",
    "        stats = {\n",
    "            \"all\": {\n",
    "                \"protonated\": compute_stats(last50_files, protonated_residue),\n",
    "                \"neutral\": compute_stats(last50_files, neutral_residue)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        result_entry = {\"folder_name\": protonated_trajectory_name}\n",
    "        for chunk in [\"all\"]:\n",
    "            for res_type in [\"protonated\", \"neutral\"]:\n",
    "                result_entry[f\"mean_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"mean\"]\n",
    "                result_entry[f\"std_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std\"]\n",
    "                result_entry[f\"sem_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"sem\"]\n",
    "                result_entry[f\"std_per_frame_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std_per_frame\"]\n",
    "                result_entry[f\"std_per_molecule_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std_per_molecule\"]\n",
    "\n",
    "        u = None\n",
    "        del u\n",
    "\n",
    "        return result_entry\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {protonated_trajectory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -- Progress bar integration --\n",
    "class TqdmBackend(LokyBackend):\n",
    "    def __init__(self, tqdm_bar, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tqdm_bar = tqdm_bar\n",
    "\n",
    "    def apply_async(self, func, callback=None):\n",
    "        return super().apply_async(\n",
    "            func,\n",
    "            callback=lambda *a, **k: (\n",
    "                callback and callback(*a, **k),\n",
    "                self.tqdm_bar.update()\n",
    "            )[1]\n",
    "        )\n",
    "\n",
    "# Initialize tqdm bar\n",
    "progress_bar = tqdm(total=len(batch_names), desc=\"Processing batch\", position=0)\n",
    "\n",
    "# Use custom backend instance manually\n",
    "backend = TqdmBackend(progress_bar)\n",
    "\n",
    "with JoblibParallel(n_jobs=NUM_CPU, backend=backend) as parallel:\n",
    "    results = parallel(\n",
    "        delayed(process_trajectory)(name, dir_)\n",
    "        for name, dir_ in zip(batch_names, batch_dirs)\n",
    "    )\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# Remove any failed jobs\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(results).to_csv(PROTONATED_OUTPUT_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2782c88d-64dc-43e2-b0ee-983f6f8d534b",
   "metadata": {},
   "source": [
    "## Fully-neutral systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd63ab55-5cd3-4828-a216-63bd80314751",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_names = neutral_trajectory_names\n",
    "batch_dirs = neutral_trajectory_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751032af-306d-4668-bf36-5969312acba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_trajectory(neutral_trajectory_name, neutral_trajectory_dir):\n",
    "    try:\n",
    "        dcd_files = [f for f in os.listdir(neutral_trajectory_dir) if f.endswith(\".dcd\")]\n",
    "        dcd_indices = sorted([\n",
    "            int(f.split(\"_\")[1].split(\".\")[0])\n",
    "            for f in dcd_files\n",
    "            if f.split(\"_\")[1].split(\".\")[0].isdigit()\n",
    "        ], reverse=True)\n",
    "        last50_files = [os.path.join(neutral_trajectory_dir, f\"step3_{i}.dcd\") for i in range(150, 100, -1)]\n",
    "\n",
    "        topology_file = os.path.join(os.path.dirname(neutral_trajectory_dir), \"openmm\", \"system.psf\")\n",
    "\n",
    "        u = mda.Universe(topology_file, last50_files[0])\n",
    "        protonated_residue, neutral_residue = identify_residues(u, excluded_residues)\n",
    "\n",
    "        il_row = il_atom_dict[il_atom_dict[\"folder_name\"] == neutral_trajectory_name].iloc[0]\n",
    "        head_atoms = il_row[\"head_total\"].split(\",\") if isinstance(il_row[\"head_total\"], str) else []\n",
    "        anchor_atom = il_row[\"anchor_atom\"].split(\",\") if isinstance(il_row[\"anchor_atom\"], str) else []\n",
    "        tail1_ends = il_row[\"tail1_terminal\"].split(\",\") if isinstance(il_row[\"tail1_terminal\"], str) else []\n",
    "        tail2_ends = il_row[\"tail2_terminal\"].split(\",\") if isinstance(il_row[\"tail2_terminal\"], str) else []\n",
    "        tail3_ends = []\n",
    "\n",
    "        def compute_stats(dcd_list, residue):\n",
    "            cpp = compute_cpp_for_residue(\n",
    "                dcd_list, topology_file, residue, head_atoms, anchor_atom, tail1_ends, tail2_ends, tail3_ends\n",
    "            )\n",
    "        \n",
    "            # cpp is (n_frames, n_molecules)\n",
    "            frame_means = np.nanmean(cpp, axis=1)  #row-wise mean across molecules for each frame\n",
    "            molecule_means = np.nanmean(cpp, axis=0) #column-wise mean across frames for each molecule\n",
    "            std_per_frame = np.nanstd(frame_means)\n",
    "            std_per_molecule = np.nanstd(molecule_means)\n",
    "        \n",
    "            #cpp_clean = remove_outliers(cpp)\n",
    "            cpp_clean = cpp\n",
    "        \n",
    "            return {\n",
    "                \"mean\": np.mean(cpp_clean),\n",
    "                \"std\": np.std(cpp_clean),\n",
    "                \"sem\": np.std(cpp_clean) / np.sqrt(len(cpp_clean)) if len(cpp_clean) > 0 else np.nan,\n",
    "                \"std_per_frame\": std_per_frame,\n",
    "                \"std_per_molecule\": std_per_molecule\n",
    "            }\n",
    "    \n",
    "        # Compute stats for each chunk + combined \"all\"\n",
    "        stats = {\n",
    "            \"all\": {\n",
    "                \"neutral\": compute_stats(last50_files, neutral_residue)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        result_entry = {\"folder_name\": neutral_trajectory_name}\n",
    "        for chunk in [\"all\"]:\n",
    "            for res_type in [\"neutral\"]:\n",
    "                result_entry[f\"mean_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"mean\"]\n",
    "                result_entry[f\"std_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std\"]\n",
    "                result_entry[f\"sem_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"sem\"]\n",
    "                result_entry[f\"std_per_frame_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std_per_frame\"]\n",
    "                result_entry[f\"std_per_molecule_cpp_{res_type}_{chunk}\"] = stats[chunk][res_type][\"std_per_molecule\"]\n",
    "\n",
    "        u = None\n",
    "        del u\n",
    "        \n",
    "        return result_entry\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {neutral_trajectory_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# -- Progress bar integration --\n",
    "class TqdmBackend(LokyBackend):\n",
    "    def __init__(self, tqdm_bar, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.tqdm_bar = tqdm_bar\n",
    "\n",
    "    def apply_async(self, func, callback=None):\n",
    "        return super().apply_async(\n",
    "            func,\n",
    "            callback=lambda *a, **k: (\n",
    "                callback and callback(*a, **k),\n",
    "                self.tqdm_bar.update()\n",
    "            )[1]\n",
    "        )\n",
    "\n",
    "# Initialize tqdm bar\n",
    "progress_bar = tqdm(total=len(batch_names), desc=\"Processing batch\", position=0)\n",
    "\n",
    "# Use custom backend instance manually\n",
    "backend = TqdmBackend(progress_bar)\n",
    "\n",
    "with JoblibParallel(n_jobs=NUM_CPU, backend=backend) as parallel:\n",
    "    results = parallel(\n",
    "        delayed(process_trajectory)(name, dir_)\n",
    "        for name, dir_ in zip(batch_names, batch_dirs)\n",
    "    )\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "# Remove any failed jobs\n",
    "results = [r for r in results if r is not None]\n",
    "\n",
    "# Save to CSV\n",
    "pd.DataFrame(results).to_csv(NEUTRAL_OUTPUT_FILE, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
